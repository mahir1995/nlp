{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextCNN_torch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahir1995/nlp/blob/master/TextCNN_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pGost9fXhm8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMaibyixh0hU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TextCNN parameters\n",
        "embedding_size = 2\n",
        "seq_length = 3\n",
        "num_classes = 2\n",
        "filter_sizes = [2,2,2]\n",
        "num_filters = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGKMUjKOig1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
        "labels = [1, 1, 1, 0, 0, 0] # 1 is good, 0 is bad\n",
        "classes = ['bad', 'good']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7VyFWalikqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2936a0e9-266a-439c-ca9f-0e52e66dc5ab"
      },
      "cell_type": "code",
      "source": [
        "word_list = list(set(' '.join(sentences).split()))\n",
        "word_list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hate',\n",
              " 'for',\n",
              " 'me',\n",
              " 'loves',\n",
              " 'sorry',\n",
              " 'this',\n",
              " 'that',\n",
              " 'awful',\n",
              " 'i',\n",
              " 'baseball',\n",
              " 'is',\n",
              " 'likes',\n",
              " 'love',\n",
              " 'you',\n",
              " 'he',\n",
              " 'she']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "StKvqMVAi291",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5b370599-98a4-4319-b990-06b4a6b85cb2"
      },
      "cell_type": "code",
      "source": [
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "word_dict"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'awful': 7,\n",
              " 'baseball': 9,\n",
              " 'for': 1,\n",
              " 'hate': 0,\n",
              " 'he': 14,\n",
              " 'i': 8,\n",
              " 'is': 10,\n",
              " 'likes': 11,\n",
              " 'love': 12,\n",
              " 'loves': 3,\n",
              " 'me': 2,\n",
              " 'she': 15,\n",
              " 'sorry': 4,\n",
              " 'that': 6,\n",
              " 'this': 5,\n",
              " 'you': 13}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Swm4tMmHjBlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "026d52d8-ade5-4036-b505-5e10c2feb61a"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_dict)\n",
        "vocab_size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "9t7Ak2uljIHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6992e144-d72c-4a2e-d119-f85fb021f547"
      },
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "for sen in sentences:\n",
        "    inputs.append(np.asarray([word_dict[n] for n in sen.split()]))\n",
        "inputs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 8, 12, 13]),\n",
              " array([14,  3,  2]),\n",
              " array([15, 11,  9]),\n",
              " array([ 8,  0, 13]),\n",
              " array([4, 1, 6]),\n",
              " array([ 5, 10,  7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "B9KqEo2bjfYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2653a718-9a85-4ce2-b342-ed4cc6aac38a"
      },
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "for out in labels:\n",
        "    targets.append(out)\n",
        "targets"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "3M0QVhDGjoNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_batch = Variable(torch.LongTensor(inputs))\n",
        "target_batch = Variable(torch.LongTensor(targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_409AwLj5q3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextCNN, self).__init__()\n",
        "        \n",
        "        self.num_filters_total = num_filters * len(filter_sizes)\n",
        "        self.W = nn.Parameter(torch.empty(vocab_size, embedding_size).uniform_(-1, 1)).type(torch.FloatTensor)\n",
        "        self.weight = nn.Parameter(torch.empty(self.num_filters_total, num_classes).uniform_(-1, 1)).type(torch.FloatTensor)\n",
        "        self.bias = nn.Parameter(0.1 * torch.ones([num_classes])).type(torch.FloatTensor)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embedded_chars = self.W[x]\n",
        "        embedded_chars = embedded_chars.unsqueeze(1)\n",
        "        \n",
        "        pooled_outputs = []\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = nn.Conv2d(1, num_filters, (filter_size, embedding_size), bias=True)(embedded_chars)\n",
        "            h = F.relu(conv)\n",
        "            mp = nn.MaxPool2d((seq_length - filter_size + 1, 1))\n",
        "            pooled = mp(h).permute(0,3, 2, 1)\n",
        "            pooled_outputs.append(pooled)\n",
        "            \n",
        "        h_pool = torch.cat(pooled_outputs, len(filter_sizes))\n",
        "        h_pool_flat = torch.reshape(h_pool, [-1, self.num_filters_total])\n",
        "        \n",
        "        model = torch.mm(h_pool_flat, self.weight) + self.bias\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TSqXHdnm0qM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TextCNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bY5a1r-jm4s3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QLXN8lJndZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "97d209fa-d4d8-4e54-9ad4-44e942b61c7b"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(5000):\n",
        "    opt.zero_grad()\n",
        "    output = model(input_batch)\n",
        "    loss = criterion(output, target_batch)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    if (epoch+1)%1000 == 0:\n",
        "        print('Epoch:', epoch, 'Loss:', loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 999 Loss: tensor(0.4168, grad_fn=<NllLossBackward>)\n",
            "Epoch: 1999 Loss: tensor(0.1275, grad_fn=<NllLossBackward>)\n",
            "Epoch: 2999 Loss: tensor(0.0489, grad_fn=<NllLossBackward>)\n",
            "Epoch: 3999 Loss: tensor(0.0754, grad_fn=<NllLossBackward>)\n",
            "Epoch: 4999 Loss: tensor(0.0190, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jcu3uP4in0w3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = 'sorry i hate you'\n",
        "test = [np.asarray([word_dict[n] for n in test.split()])]\n",
        "test_batch = Variable(torch.LongTensor(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "taEutNfvoXK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict = model(test_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jz-1IcVzoa_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "458ae22d-5ce8-4a7f-8008-3b99c0e30060"
      },
      "cell_type": "code",
      "source": [
        "prediction = predict.data.max(1, keepdim=True)[1]\n",
        "classes[prediction]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "G54blBCwo8xb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}